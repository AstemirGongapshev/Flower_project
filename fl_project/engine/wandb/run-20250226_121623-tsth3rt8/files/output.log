[I 2025-02-26 12:16:24,558] A new study created in memory with name: no-name-bf4ad34d-0d0f-40a6-a4e3-d28c7321e0fd
[I 2025-02-26 12:16:26,113] Trial 0 finished with value: 0.6956491838939632 and parameters: {'model': 'LogisticRegressionModel', 'optimizer': 'AdamW', 'learning_rate': 0.000830381176799219, 'num_epochs': 16}. Best is trial 0 with value: 0.6956491838939632.
[I 2025-02-26 12:16:27,184] Trial 1 finished with value: 0.5006524142948406 and parameters: {'model': 'LogisticRegressionModel', 'optimizer': 'Adam', 'learning_rate': 0.00026140124507485925, 'num_epochs': 13}. Best is trial 0 with value: 0.6956491838939632.
[I 2025-02-26 12:16:28,276] Trial 2 finished with value: 0.7273541659503079 and parameters: {'model': 'LogisticRegressionModel', 'optimizer': 'AdamW', 'learning_rate': 0.002638057278773385, 'num_epochs': 10}. Best is trial 2 with value: 0.7273541659503079.
[I 2025-02-26 12:16:28,903] Trial 3 finished with value: 0.5928952897678637 and parameters: {'model': 'LogisticRegressionModel', 'optimizer': 'SGD', 'learning_rate': 2.5812458532111934e-05, 'num_epochs': 5}. Best is trial 2 with value: 0.7273541659503079.
[I 2025-02-26 12:16:30,890] Trial 4 finished with value: 0.7797101868927163 and parameters: {'model': 'MLPModel', 'optimizer': 'AdamW', 'learning_rate': 0.00231550558287293, 'num_epochs': 20}. Best is trial 4 with value: 0.7797101868927163.
[I 2025-02-26 12:16:32,264] Trial 5 finished with value: 0.7481771309334864 and parameters: {'model': 'MLPModel', 'optimizer': 'Adam', 'learning_rate': 0.00037036460559484015, 'num_epochs': 10}. Best is trial 4 with value: 0.7797101868927163.
[I 2025-02-26 12:16:33,721] Trial 6 finished with value: 0.7403409204018365 and parameters: {'model': 'MLPModel', 'optimizer': 'AdamW', 'learning_rate': 0.00030388780039167316, 'num_epochs': 14}. Best is trial 4 with value: 0.7797101868927163.
[I 2025-02-26 12:16:35,388] Trial 7 finished with value: 0.7588510269417243 and parameters: {'model': 'LogisticRegressionModel', 'optimizer': 'Adam', 'learning_rate': 0.0027053099937902635, 'num_epochs': 22}. Best is trial 4 with value: 0.7797101868927163.
[I 2025-02-26 12:16:37,245] Trial 8 finished with value: 0.769821721686034 and parameters: {'model': 'MLPModel', 'optimizer': 'AdamW', 'learning_rate': 0.002815527851363439, 'num_epochs': 17}. Best is trial 4 with value: 0.7797101868927163.
[I 2025-02-26 12:16:38,130] Trial 9 finished with value: 0.6358315703367761 and parameters: {'model': 'MLPModel', 'optimizer': 'RMSProp', 'learning_rate': 8.201986025581059e-05, 'num_epochs': 6}. Best is trial 4 with value: 0.7797101868927163.
[I 2025-02-26 12:16:40,766] Trial 10 finished with value: 0.7806666389171913 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.007410704881591995, 'num_epochs': 28}. Best is trial 10 with value: 0.7806666389171913.
[I 2025-02-26 12:16:43,391] Trial 11 finished with value: 0.7857167418013873 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.009533195378526416, 'num_epochs': 30}. Best is trial 11 with value: 0.7857167418013873.
[I 2025-02-26 12:16:46,149] Trial 12 finished with value: 0.7857954658563819 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.007196390201784836, 'num_epochs': 30}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:16:48,593] Trial 13 finished with value: 0.7828645783376738 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.009195685221605479, 'num_epochs': 29}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:16:50,943] Trial 14 finished with value: 0.7768534990580259 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.009166612637874624, 'num_epochs': 25}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:16:53,898] Trial 15 finished with value: 0.6094562972909876 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 1.0403216374102402e-05, 'num_epochs': 30}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:16:56,307] Trial 16 finished with value: 0.7689168474906933 and parameters: {'model': 'MLPModel', 'optimizer': 'RMSProp', 'learning_rate': 0.0008769537113044196, 'num_epochs': 25}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:16:58,494] Trial 17 finished with value: 0.7717255769930308 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.0012284303642005035, 'num_epochs': 25}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:17:00,642] Trial 18 finished with value: 0.7829279195313475 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.006088666532941216, 'num_epochs': 21}. Best is trial 12 with value: 0.7857954658563819.
[I 2025-02-26 12:17:03,057] Trial 19 finished with value: 0.7292679748734534 and parameters: {'model': 'MLPModel', 'optimizer': 'SGD', 'learning_rate': 0.0001122800121757648, 'num_epochs': 27}. Best is trial 12 with value: 0.7857954658563819.
