{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import entropy\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, roc_auc_score\n",
    "from model import LogisticRegressionModel, MLPModel\n",
    "from tools import train, eval, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join( \"data\", \"IID.csv\"))\n",
    "test_data = pd.read_csv(os.path.join( \"data\", \"TEST_SAMPLE.csv\"))\n",
    "\n",
    "df_1 = pd.read_csv(os.path.join( \"data\", \"df1.csv\"))\n",
    "df_2 = pd.read_csv(os.path.join( \"data\", \"df2.csv\"))\n",
    "df_3 = pd.read_csv(os.path.join( \"data\", \"df3.csv\"))\n",
    "df_4 = pd.read_csv(os.path.join( \"data\", \"df4.csv\"))\n",
    "df_5 = pd.read_csv(os.path.join( \"data\", \"df5.csv\"))\n",
    "df_6 = pd.read_csv(os.path.join( \"data\", \"df6.csv\"))\n",
    "\n",
    "non_iid_df_1 =pd.read_csv(os.path.join( \"data\", \"noniid_df_1.csv\"))\n",
    "non_iid_df_2 =pd.read_csv(os.path.join( \"data\", \"noniid_df_2.csv\"))\n",
    "non_iid_df_3 = pd.read_csv(os.path.join( \"data\", \"noniid_df_3.csv\"))\n",
    "non_iid_df_4 = pd.read_csv(os.path.join( \"data\", \"noniid_df_4.csv\"))\n",
    "non_iid_df_5 =pd.read_csv(os.path.join( \"data\", \"noniid_df_5.csv\"))\n",
    "non_iid_df_6 = pd.read_csv(os.path.join( \"data\", \"noniid_df_6.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_skew_split(df, feature_cols, n_clients=6, n_clusters=10, seed=42):\n",
    "    np.random.seed(seed)\n",
    "  \n",
    "    df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    X_scaled = StandardScaler().fit_transform(df_shuffled[feature_cols].values)\n",
    "    \n",
    "    clusters = KMeans(n_clusters=n_clusters, random_state=seed).fit_predict(X_scaled)\n",
    "    df_shuffled['cluster'] = clusters\n",
    "    \n",
    "    cluster_counts = (df_shuffled.groupby('cluster').size()\n",
    "                      .reset_index(name='count')\n",
    "                      .sort_values(by='count', ascending=False)\n",
    "                      .reset_index(drop=True))\n",
    "    \n",
    "    client_cluster_num = [n_clusters // n_clients + (1 if i < n_clusters % n_clients else 0) for i in range(n_clients)]\n",
    "   \n",
    "    cluster_assignment = {\n",
    "        cluster_counts.loc[idx, 'cluster']: client_id \n",
    "        for client_id in range(n_clients)\n",
    "        for idx in range(sum(client_cluster_num[:client_id]), sum(client_cluster_num[:client_id]) + client_cluster_num[client_id])\n",
    "    }\n",
    "\n",
    "    client_dfs = {\n",
    "        client_id: df_shuffled[df_shuffled['cluster'].map(cluster_assignment) == client_id].drop(columns='cluster').copy()\n",
    "        for client_id in range(n_clients)\n",
    "    }\n",
    "    return client_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DayOfWeek',\n",
       " 'Make',\n",
       " 'AccidentArea',\n",
       " 'DayOfWeekClaimed',\n",
       " 'MonthClaimed',\n",
       " 'WeekOfMonthClaimed',\n",
       " 'Sex',\n",
       " 'MaritalStatus',\n",
       " 'Age',\n",
       " 'Fault']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.columns.to_list())[2:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_dfs = feature_skew_split(train_data, (train_data.columns.to_list())[2:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotting(df):\n",
    "    features = list(next(iter(df.values())).columns)\n",
    "    sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "    for feature in features:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        [df[i][feature].hist(ax=axes[0], alpha=0.5, label=f'Client {i}', bins=20) for i in df]\n",
    "        axes[0].set(title=f'Histogram of {feature}', xlabel=feature, ylabel=\"Frequency\"); axes[0].legend()\n",
    "        [sns.kdeplot(df[i][feature], ax=axes[1], label=f'Client {i}', fill=True, alpha=0.3) for i in df]\n",
    "        axes[1].set(title=f'KDE Plot of {feature}', xlabel=feature, ylabel=\"Density\"); axes[1].legend()\n",
    "        sns.boxplot(x='client', y=feature, data=pd.concat([df[i].assign(client=f'Client {i}') for i in df]), ax=axes[2])\n",
    "        axes[2].set(title=f'Boxplot of {feature}', xlabel=\"Client\", ylabel=feature)\n",
    "        \n",
    "        plt.suptitle(f'Comparison of {feature} across clients', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting(clients_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datasets = {\n",
    "    \"df1_iid\": (df_1, test_data),\n",
    "    \"df2_iid\": (df_2, test_data),\n",
    "    \"df3_iid\": (df_3, test_data),\n",
    "    \"df4_iid\": (df_4, test_data),\n",
    "    \"df5_iid\": (df_5, test_data),\n",
    "    \"df6_iid\": (df_6, test_data),\n",
    "    \"df1_noniid\": (non_iid_df_1, test_data),\n",
    "    \"df2_noniid\": (non_iid_df_2, test_data),\n",
    "    \"df3_noniid\": (non_iid_df_3, test_data),\n",
    "    \"df4_noniid\": (non_iid_df_4, test_data),\n",
    "    \"df5_noniid\": (non_iid_df_5, test_data),\n",
    "    \"df6_noniid\": (non_iid_df_6, test_data)\n",
    "}\n",
    "\n",
    "def objective(trial, train_data, test_data):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_loader, test_loader, input_dim = prepare_data(train_data, test_data.drop(columns=\"Fraud\"), test_data.Fraud)\n",
    "    model = LogisticRegressionModel(input_dim).to(device)\n",
    "    \n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"AdamW\"])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.5, 0.99)\n",
    "    \n",
    "    if optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(5):\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Оценка модели\n",
    "    model.eval()\n",
    "    test_labels = []\n",
    "    test_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            test_labels.extend(y.cpu().numpy())\n",
    "            test_predictions.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    try:\n",
    "        test_logloss = log_loss(test_labels, test_predictions)\n",
    "        test_roc_auc = roc_auc_score(test_labels, test_predictions)\n",
    "        test_pred_binary = (np.array(test_predictions) > 0.5).astype(int)\n",
    "        test_accuracy = accuracy_score(test_labels, test_pred_binary)\n",
    "        test_f1 = f1_score(test_labels, test_pred_binary)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"lr\": lr,\n",
    "            \"momentum\": momentum,\n",
    "            \"optimizer\": optimizer_name,\n",
    "            \"roc_auc\": test_roc_auc,\n",
    "            \"accuracy\": test_accuracy,\n",
    "            \"f1_score\": test_f1,\n",
    "            \"loss\": test_logloss,\n",
    "        })\n",
    "        \n",
    "        return test_roc_auc  \n",
    "    except ValueError:\n",
    "        return float(\"-inf\")  \n",
    "\n",
    "for dataset_name, (train_data, test_data) in datasets.items():\n",
    "    wandb.init(project=\"my-first-project\", name=dataset_name)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, train_data, test_data), n_trials=20)\n",
    "    print(f\"Лучшие параметры для {dataset_name}:\", study.best_params)\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
